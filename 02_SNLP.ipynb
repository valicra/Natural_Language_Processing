{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_corpus(path_to_file): \n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    f = open(path_to_file)\n",
    "    \n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break  #Checks if the variable line is empty, which would indicate the end of the file. \n",
    "        #If the condition is true, it breaks out of the loop using the break statement.\n",
    "            \n",
    "        line = line.strip()\n",
    "        line = line.lower() # i added this \n",
    "        if len(line) == 0:\n",
    "            sentences.append(sentence)    \n",
    "            sentence = []\n",
    "            continue\n",
    "                \n",
    "        parts = line.split(' ')\n",
    "        sentence.append((parts[0], parts[-1]))\n",
    "        \n",
    "    f.close()        \n",
    "    return sentences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_words(corpus): # to get th list wof words with frequency=1\n",
    "    freqs={}\n",
    "    one_words=set()\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word[0] in freqs:\n",
    "                freqs[word[0]]+=1\n",
    "            else:\n",
    "                freqs[word[0]]=1\n",
    "\n",
    "    for k,v in freqs.items():\n",
    "        if v==1:\n",
    "            one_words.add(k)\n",
    "\n",
    "\n",
    "    return one_words\n",
    "\n",
    "def get_states(corpus): # to get the list of states\n",
    "    states=[]\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word[1] not in states:\n",
    "                states.append(word[1])\n",
    "    \n",
    "    return states \n",
    "\n",
    "\n",
    "def get_tokens(corpus): # to get the list of tokens (i.e. words)\n",
    "\n",
    "    tokens=set()\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            tokens.add(word[0])\n",
    "            \n",
    "    return tokens \n",
    "\n",
    "def change_corpus(corpus,one_words): # to add the unknown words\n",
    "    for sentence in corpus:\n",
    "        for i,word in enumerate(sentence):\n",
    "            if word[0] in one_words :\n",
    "                sentence[i] = ('unknown', word[1])\n",
    "\n",
    "    return corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 ###################################################################\n",
    "# ho cambiato leggermente la logica con cui usare queste funzioni:\n",
    "# prima calcolo i parametri del modello per tutti gli stati e token con le funzioni estimate_...()\n",
    "# poi con le funzioni non estimate_...() ci calcoliamo solo le prob degli stati/token che ci servono\n",
    "# se ci fai caso le funzioni non estimate_...() prendono come input anche internal_representation, che è l'output delle funzioni estimate_...()\n",
    "# questa è la soluzione che ho trovato per usare anche sto internal_representation di cui non sapevamo farcene\n",
    "\n",
    "'''\n",
    "Implement the probability distribution of the initial states.\n",
    "Parameters:\tstate: string\n",
    "            internal_representation: data structure representing the parameterization of this probability distribuion;\n",
    "                this data structure is returned by the function estimate_initial_state_probabilities\n",
    "Returns: float; initial probability of the given state\n",
    "'''\n",
    "def initial_state_probabilities(state, internal_representation):\n",
    "    return internal_representation[state]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement the matrix of transition probabilities.\n",
    "Parameters:\tfrom_state: string;\n",
    "            to_state: string;\n",
    "            internal_representation: data structure representing the parameterization of the matrix of transition probabilities;\n",
    "                this data structure is returned by the function estimate_transition_probabilities\n",
    "Returns: float; probability of transition from_state -> to_state\n",
    "'''\n",
    "def transition_probabilities(from_state, to_state, internal_representation):\n",
    "    return internal_representation[f'{from_state} , {to_state}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement the matrix of emmision probabilities.\n",
    "Parameters:\tstate: string;\n",
    "            emission_symbol: string;\n",
    "            internal_representation: data structure representing the parameterization of the matrix of emission probabilities;\n",
    "                this data structure is returned by the function estimate_emission_probabilities\n",
    "Returns: float; emission probability of the symbol emission_symbol if the current state is state\n",
    "'''\n",
    "def emission_probabilities(state, emission_symbol, internal_representation):\n",
    "    return internal_representation[f'{state} , {emission_symbol}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the probability distribution of the initial states.\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the probability distribution of the initial states;\n",
    "            use this data structure for the argument internal_representation of the function initial_state_probabilities\n",
    "'''\n",
    "def estimate_initial_state_probabilities(states,corpus):\n",
    "\n",
    "    probs= {}\n",
    "\n",
    "    for state in states:\n",
    "        prob = {state:0} \n",
    "        count=0 # counts every start \n",
    "\n",
    "        for sentence in corpus:\n",
    "            count+=1 \n",
    "            if sentence[0][1]==state: # check for the first state in each sentence\n",
    "                prob[state]+=1\n",
    "    \n",
    "        prob[state] /= count\n",
    "\n",
    "        probs.update(prob)\n",
    "\n",
    "\n",
    "    return probs\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the matrix of transition probabilities\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the matrix of transition probabilities;\n",
    "            use this data structure for the argument internal_representation of the function transition_probabilities\n",
    "'''\n",
    "def estimate_transition_probabilities(states,corpus):\n",
    "    probs={}\n",
    "    for state1 in states:\n",
    "        for state2 in states:\n",
    "            from_freq=0 # counts how many times the from_state has a next state\n",
    "            joint_freq=0 # counts how many times the from_state has as to_state as a next state \n",
    "\n",
    "            for sentence in corpus:\n",
    "                for i,word in enumerate(sentence[:-1]): # we ingore the last word/tag since doesn't have a next state \n",
    "                    if word[1]==state1:\n",
    "                        from_freq+=1\n",
    "                        if sentence[i+1][1]==state2:\n",
    "                            joint_freq+=1\n",
    "\n",
    "    \n",
    "            prob={f'{state1} , {state2}':joint_freq/from_freq}\n",
    "\n",
    "            probs.update(prob)\n",
    "\n",
    "    return probs\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the matrix of emission probabilities\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the matrix of emission probabilities;\n",
    "            use this data structure for the argument internal_representation of the function emission_probabilities\n",
    "'''\n",
    "def estimate_emission_probabilities(states,tokens,corpus):\n",
    "    probs={}\n",
    "\n",
    "    for state in states:\n",
    "        for token in tokens:\n",
    "            state_count=0 # counts occurence of the state\n",
    "            st_sy_count=0 # joint frequency of state and symbol \n",
    "\n",
    "            for sentence in corpus:\n",
    "                for word in sentence:\n",
    "                    if word[1]==state:\n",
    "                        state_count+=1\n",
    "                        if word[0]==token:\n",
    "                            st_sy_count+=1\n",
    "\n",
    "\n",
    "            prob={f'{state} , {token}':st_sy_count/state_count}\n",
    "\n",
    "            probs.update(prob)\n",
    "            \n",
    "    \n",
    "    return probs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=import_corpus('corpus_ner.txt')\n",
    "one_words=get_one_words(corpus)\n",
    "corpus=change_corpus(corpus,one_words)\n",
    "states=get_states(corpus)\n",
    "tokens=get_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es_init_prob=estimate_initial_state_probabilities(states, corpus)\n",
    "es_trans_prob=estimate_transition_probabilities(states, corpus)\n",
    "es_emiss_prob=estimate_emission_probabilities(states,tokens, corpus)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
