{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors: \n",
    "- Vali Florinel Craciun\n",
    "- Ilaria Salvatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to run the code:\n",
    "# we first defined the estimate...() functions \n",
    "# each estimate...() function will return the internal state representation, to be then used as inputs for non estimate functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def import_corpus(path_to_file): \n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    f = open(path_to_file)\n",
    "    \n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break  #Checks if the variable line is empty, which would indicate the end of the file. \n",
    "        #If the condition is true, it breaks out of the loop using the break statement.\n",
    "            \n",
    "        line = line.strip()\n",
    "        line = line.lower() # i added this \n",
    "        if len(line) == 0:\n",
    "            sentences.append(sentence)    \n",
    "            sentence = []\n",
    "            continue\n",
    "                \n",
    "        parts = line.split(' ')\n",
    "        sentence.append((parts[0], parts[-1]))\n",
    "        \n",
    "    f.close()        \n",
    "    return sentences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some useful functions\n",
    "\n",
    "def get_one_words(corpus): # to get th list wof words with frequency=1\n",
    "    freqs={}\n",
    "    one_words=set()\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word[0] in freqs:\n",
    "                freqs[word[0]]+=1\n",
    "            else:\n",
    "                freqs[word[0]]=1\n",
    "\n",
    "    for k,v in freqs.items():\n",
    "        if v==1:\n",
    "            one_words.add(k)\n",
    "\n",
    "\n",
    "    return one_words\n",
    "\n",
    "def get_states(corpus): # to get the list of distinct states\n",
    "    states=[]\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word[1] not in states:\n",
    "                states.append(word[1])\n",
    "    \n",
    "    return states \n",
    "\n",
    "\n",
    "def get_tokens(corpus): # to get the list of distinct tokens (i.e. words)\n",
    "\n",
    "    tokens=set()\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            tokens.add(word[0])\n",
    "            \n",
    "    return tokens \n",
    "\n",
    "def change_corpus(corpus,one_words): # to add the unknown words\n",
    "    for sentence in corpus:\n",
    "        for i,word in enumerate(sentence):\n",
    "            if word[0] in one_words :\n",
    "                sentence[i] = ('unknown', word[1])\n",
    "\n",
    "    return corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 ###################################################################\n",
    "'''\n",
    "Implement the probability distribution of the initial states.\n",
    "Parameters:\tstate: string\n",
    "            internal_representation: data structure representing the parameterization of this probability distribuion;\n",
    "                this data structure is returned by the function estimate_initial_state_probabilities\n",
    "Returns: float; initial probability of the given state\n",
    "'''\n",
    "def initial_state_probabilities(state, internal_representation):\n",
    "    return internal_representation[state]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement the matrix of transition probabilities.\n",
    "Parameters:\tfrom_state: string;\n",
    "            to_state: string;\n",
    "            internal_representation: data structure representing the parameterization of the matrix of transition probabilities;\n",
    "                this data structure is returned by the function estimate_transition_probabilities\n",
    "Returns: float; probability of transition from_state -> to_state\n",
    "'''\n",
    "def transition_probabilities(from_state, to_state, internal_representation):\n",
    "    return internal_representation[f'{from_state} , {to_state}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement the matrix of emmision probabilities.\n",
    "Parameters:\tstate: string;\n",
    "            emission_symbol: string;\n",
    "            internal_representation: data structure representing the parameterization of the matrix of emission probabilities;\n",
    "                this data structure is returned by the function estimate_emission_probabilities\n",
    "Returns: float; emission probability of the symbol emission_symbol if the current state is state\n",
    "'''\n",
    "def emission_probabilities(state, emission_symbol, internal_representation):\n",
    "    return internal_representation[f'{state} , {emission_symbol}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the probability distribution of the initial states.\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the probability distribution of the initial states;\n",
    "            use this data structure for the argument internal_representation of the function initial_state_probabilities\n",
    "'''\n",
    "def estimate_initial_state_probabilities(states,corpus):\n",
    "\n",
    "    e=1e-5\n",
    "    probs= {}\n",
    "\n",
    "    for state in states:\n",
    "        prob = {state:e} \n",
    "        count=0 # counts every start \n",
    "\n",
    "        for sentence in corpus:\n",
    "            count+=1 # number of sentences \n",
    "            if sentence[0][1]==state: # check for the first state in each sentence\n",
    "                prob[state]+=1\n",
    "    \n",
    "        \n",
    "        prob[state] /= (count + e*len(states)) # now becomes a prob. \n",
    "\n",
    "        probs.update(prob) \n",
    "\n",
    "\n",
    "    return probs\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the matrix of transition probabilities\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the matrix of transition probabilities;\n",
    "            use this data structure for the argument internal_representation of the function transition_probabilities\n",
    "'''\n",
    "def estimate_transition_probabilities(states,corpus):\n",
    "    e=1e-5\n",
    "    probs={}\n",
    "    for state1 in states:\n",
    "        for state2 in states:\n",
    "            from_freq=0 # counts how many times the from_state has a next state \n",
    "            joint_freq=0 # counts how many times the from_state has as to_state as a next state \n",
    "\n",
    "            for sentence in corpus:\n",
    "                for i,word in enumerate(sentence[:-1]): # we ignore the last word/tag since doesn't have a next state \n",
    "                    if word[1]==state1:\n",
    "                        from_freq+=1\n",
    "                        if sentence[i+1][1]==state2:\n",
    "                            joint_freq+=1\n",
    "\n",
    "    \n",
    "            prob={f'{state1} , {state2}':(joint_freq+e)/from_freq+e} # laplace smoothing\n",
    "\n",
    "            probs.update(prob)\n",
    "\n",
    "    return probs\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Implement a function for estimating the parameters of the matrix of emission probabilities\n",
    "Parameters: corpus: list returned by the function import_corpus\n",
    "Returns: data structure containing the parameters of the matrix of emission probabilities;\n",
    "            use this data structure for the argument internal_representation of the function emission_probabilities\n",
    "'''\n",
    "def estimate_emission_probabilities(states,tokens,corpus):\n",
    "    e = 1e-5\n",
    "    \n",
    "    probs={}\n",
    "\n",
    "    for state in states:\n",
    "        for token in tokens:\n",
    "            state_count=0 # counts occurence of the state\n",
    "            st_sy_count=0 # joint frequency of state and symbol \n",
    "\n",
    "            for sentence in corpus:\n",
    "                for word in sentence:\n",
    "                    if word[1]==state:\n",
    "                        state_count+=1\n",
    "                        if word[0]==token:\n",
    "                            st_sy_count+=1\n",
    "\n",
    "\n",
    "            prob={f'{state} , {token}':(st_sy_count+e)/(state_count+e)}\n",
    "\n",
    "            probs.update(prob)\n",
    "            \n",
    "    \n",
    "    return probs\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=import_corpus('corpus_ner.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_words=get_one_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=change_corpus(corpus,one_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=get_states(corpus)\n",
    "tokens=get_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_init_prob=estimate_initial_state_probabilities(states, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 0.6713460772098555,\n",
       " 'b-loc': 0.07984866587297254,\n",
       " 'b-per': 0.11210673038621105,\n",
       " 'b-misc': 0.051075268822583855,\n",
       " 'i-misc': 9.956192750999544e-12,\n",
       " 'i-per': 9.956192750999544e-12,\n",
       " 'b-org': 0.08562325766855228,\n",
       " 'i-loc': 9.956192750999544e-12,\n",
       " 'i-org': 9.956192750999544e-12}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_init_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_trans_prob=estimate_transition_probabilities(states, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o , o': 0.9041882372661988,\n",
       " 'o , b-loc': 0.02828099025380989,\n",
       " 'o , b-per': 0.026011502259072467,\n",
       " 'o , b-misc': 0.020518683489200745,\n",
       " 'o , i-misc': 1.0000054818550597e-07,\n",
       " 'o , i-per': 1.0000054818550597e-07,\n",
       " 'o , b-org': 0.02100108673445894,\n",
       " 'o , i-loc': 1.0000054818550597e-07,\n",
       " 'o , i-org': 1.0000054818550597e-07,\n",
       " 'b-loc , o': 0.8287958240855186,\n",
       " 'b-loc , b-loc': 0.0006682142642391849,\n",
       " 'b-loc , b-per': 1.000167028561884e-07,\n",
       " 'b-loc , b-misc': 0.004342842625688993,\n",
       " 'b-loc , i-misc': 1.000167028561884e-07,\n",
       " 'b-loc , i-per': 1.000167028561884e-07,\n",
       " 'b-loc , b-org': 0.0025055284449640885,\n",
       " 'b-loc , i-loc': 0.16368809066310339,\n",
       " 'b-loc , i-org': 1.000167028561884e-07,\n",
       " 'b-per , o': 0.4495475354844116,\n",
       " 'b-per , b-loc': 0.0006705659906134764,\n",
       " 'b-per , b-per': 1.0001676164934629e-07,\n",
       " 'b-per , b-misc': 1.0001676164934629e-07,\n",
       " 'b-per , i-misc': 1.0001676164934629e-07,\n",
       " 'b-per , i-per': 0.5497821985752597,\n",
       " 'b-per , b-org': 1.0001676164934629e-07,\n",
       " 'b-per , i-loc': 1.0001676164934629e-07,\n",
       " 'b-per , i-org': 1.0001676164934629e-07,\n",
       " 'b-misc , o': 0.7427913341637831,\n",
       " 'b-misc , b-loc': 0.0025375856055363318,\n",
       " 'b-misc , b-per': 0.019146582145328717,\n",
       " 'b-misc , b-misc': 0.007843237277970011,\n",
       " 'b-misc , i-misc': 0.21730113808535179,\n",
       " 'b-misc , i-per': 1.000230680507497e-07,\n",
       " 'b-misc , b-org': 0.010380722860438292,\n",
       " 'b-misc , i-loc': 1.000230680507497e-07,\n",
       " 'b-misc , i-org': 1.000230680507497e-07,\n",
       " 'i-misc , o': 0.7329094800476946,\n",
       " 'i-misc , b-loc': 0.00158992519872814,\n",
       " 'i-misc , b-per': 0.003179750317965024,\n",
       " 'i-misc , b-misc': 0.003974662877583466,\n",
       " 'i-misc , i-misc': 0.2535772065977743,\n",
       " 'i-misc , i-per': 1.0007949125596184e-07,\n",
       " 'i-misc , b-org': 0.004769575437201908,\n",
       " 'i-misc , i-loc': 1.0007949125596184e-07,\n",
       " 'i-misc , i-org': 1.0007949125596184e-07,\n",
       " 'i-per , o': 0.9297053154478457,\n",
       " 'i-per , b-loc': 1.0002834467120182e-07,\n",
       " 'i-per , b-per': 1.0002834467120182e-07,\n",
       " 'i-per , b-misc': 1.0002834467120182e-07,\n",
       " 'i-per , i-misc': 1.0002834467120182e-07,\n",
       " 'i-per , i-per': 0.07029488460884353,\n",
       " 'i-per , b-org': 1.0002834467120182e-07,\n",
       " 'i-per , i-loc': 1.0002834467120182e-07,\n",
       " 'i-per , i-org': 1.0002834467120182e-07,\n",
       " 'b-org , o': 0.5874317940100882,\n",
       " 'b-org , b-loc': 0.0008407893862967633,\n",
       " 'b-org , b-per': 0.0006306170449768809,\n",
       " 'b-org , b-misc': 0.0018916510928961747,\n",
       " 'b-org , i-misc': 1.0002101723413198e-07,\n",
       " 'b-org , i-per': 1.0002101723413198e-07,\n",
       " 'b-org , b-org': 1.0002101723413198e-07,\n",
       " 'b-org , i-loc': 1.0002101723413198e-07,\n",
       " 'b-org , i-org': 0.4092056485708281,\n",
       " 'i-loc , o': 0.875000100089928,\n",
       " 'i-loc , b-loc': 0.0008993806654676259,\n",
       " 'i-loc , b-per': 1.0008992805755395e-07,\n",
       " 'i-loc , b-misc': 0.0017986612410071942,\n",
       " 'i-loc , i-misc': 1.0008992805755395e-07,\n",
       " 'i-loc , i-per': 1.0008992805755395e-07,\n",
       " 'i-loc , b-org': 0.0008993806654676259,\n",
       " 'i-loc , i-loc': 0.12140297778776978,\n",
       " 'i-loc , i-org': 1.0008992805755395e-07,\n",
       " 'i-org , o': 0.5807323929471788,\n",
       " 'i-org , b-loc': 1.0003001200480192e-07,\n",
       " 'i-org , b-per': 0.0015007002701080433,\n",
       " 'i-org , b-misc': 0.0009004601740696277,\n",
       " 'i-org , i-misc': 1.0003001200480192e-07,\n",
       " 'i-org , i-per': 1.0003001200480192e-07,\n",
       " 'i-org , b-org': 1.0003001200480192e-07,\n",
       " 'i-org , i-loc': 1.0003001200480192e-07,\n",
       " 'i-org , i-org': 0.4168668467286915}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_trans_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_emiss_prob=estimate_emission_probabilities(states,tokens, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o , ltte': 5.196046844858488e-10,\n",
       " 'o , raid': 2.0784706984118434e-05,\n",
       " 'o , shaken': 3.117680067383541e-05,\n",
       " 'o , kilos': 1.5588660139259947e-05,\n",
       " 'o , maynard': 5.196046844858488e-10,\n",
       " 'o , joins': 1.5588660139259947e-05,\n",
       " 'o , ours': 1.0392613294401461e-05,\n",
       " 'o , heads': 6.754912858784481e-05,\n",
       " 'o , 15-30': 1.0392613294401461e-05,\n",
       " 'o , joaquin': 5.196046844858488e-10,\n",
       " 'b-loc , ltte': 1.6702855909422817e-08,\n",
       " 'b-loc , raid': 1.6702855909422817e-08,\n",
       " 'b-loc , shaken': 1.6702855909422817e-08,\n",
       " 'b-loc , kilos': 1.6702855909422817e-08,\n",
       " 'b-loc , maynard': 1.6702855909422817e-08,\n",
       " 'b-loc , joins': 1.6702855909422817e-08,\n",
       " 'b-loc , ours': 1.6702855909422817e-08,\n",
       " 'b-loc , heads': 1.6702855909422817e-08,\n",
       " 'b-loc , 15-30': 1.6702855909422817e-08,\n",
       " 'b-loc , joaquin': 1.6702855909422817e-08,\n",
       " 'b-per , ltte': 1.676164906534279e-08,\n",
       " 'b-per , raid': 1.676164906534279e-08,\n",
       " 'b-per , shaken': 1.676164906534279e-08,\n",
       " 'b-per , kilos': 1.676164906534279e-08,\n",
       " 'b-per , maynard': 1.676164906534279e-08,\n",
       " 'b-per , joins': 1.676164906534279e-08,\n",
       " 'b-per , ours': 1.676164906534279e-08,\n",
       " 'b-per , heads': 1.676164906534279e-08,\n",
       " 'b-per , 15-30': 1.676164906534279e-08,\n",
       " 'b-per , joaquin': 0.0003352497429559212,\n",
       " 'b-misc , ltte': 2.3068050217576696e-08,\n",
       " 'b-misc , raid': 2.3068050217576696e-08,\n",
       " 'b-misc , shaken': 2.3068050217576696e-08,\n",
       " 'b-misc , kilos': 2.3068050217576696e-08,\n",
       " 'b-misc , maynard': 2.3068050217576696e-08,\n",
       " 'b-misc , joins': 2.3068050217576696e-08,\n",
       " 'b-misc , ours': 2.3068050217576696e-08,\n",
       " 'b-misc , heads': 2.3068050217576696e-08,\n",
       " 'b-misc , 15-30': 2.3068050217576696e-08,\n",
       " 'b-misc , joaquin': 2.3068050217576696e-08,\n",
       " 'i-misc , ltte': 7.930213486898218e-08,\n",
       " 'i-misc , raid': 7.930213486898218e-08,\n",
       " 'i-misc , shaken': 7.930213486898218e-08,\n",
       " 'i-misc , kilos': 7.930213486898218e-08,\n",
       " 'i-misc , maynard': 7.930213486898218e-08,\n",
       " 'i-misc , joins': 7.930213486898218e-08,\n",
       " 'i-misc , ours': 7.930213486898218e-08,\n",
       " 'i-misc , heads': 7.930213486898218e-08,\n",
       " 'i-misc , 15-30': 7.930213486898218e-08,\n",
       " 'i-misc , joaquin': 7.930213486898218e-08,\n",
       " 'i-per , ltte': 2.8344670398393696e-08,\n",
       " 'i-per , raid': 2.8344670398393696e-08,\n",
       " 'i-per , shaken': 2.8344670398393696e-08,\n",
       " 'i-per , kilos': 2.8344670398393696e-08,\n",
       " 'i-per , maynard': 0.0008503684566222093,\n",
       " 'i-per , joins': 2.8344670398393696e-08,\n",
       " 'i-per , ours': 2.8344670398393696e-08,\n",
       " 'i-per , heads': 2.8344670398393696e-08,\n",
       " 'i-per , 15-30': 2.8344670398393696e-08,\n",
       " 'i-per , joaquin': 2.8344670398393696e-08,\n",
       " 'b-org , ltte': 0.0010508827017468956,\n",
       " 'b-org , raid': 2.101723369026411e-08,\n",
       " 'b-org , shaken': 2.101723369026411e-08,\n",
       " 'b-org , kilos': 2.101723369026411e-08,\n",
       " 'b-org , maynard': 2.101723369026411e-08,\n",
       " 'b-org , joins': 2.101723369026411e-08,\n",
       " 'b-org , ours': 2.101723369026411e-08,\n",
       " 'b-org , heads': 2.101723369026411e-08,\n",
       " 'b-org , 15-30': 2.101723369026411e-08,\n",
       " 'b-org , joaquin': 2.101723369026411e-08,\n",
       " 'i-loc , ltte': 8.968609061111296e-08,\n",
       " 'i-loc , raid': 8.968609061111296e-08,\n",
       " 'i-loc , shaken': 8.968609061111296e-08,\n",
       " 'i-loc , kilos': 8.968609061111296e-08,\n",
       " 'i-loc , maynard': 8.968609061111296e-08,\n",
       " 'i-loc , joins': 8.968609061111296e-08,\n",
       " 'i-loc , ours': 8.968609061111296e-08,\n",
       " 'i-loc , heads': 8.968609061111296e-08,\n",
       " 'i-loc , 15-30': 8.968609061111296e-08,\n",
       " 'i-loc , joaquin': 8.968609061111296e-08,\n",
       " 'i-org , ltte': 2.997601828609058e-08,\n",
       " 'i-org , raid': 2.997601828609058e-08,\n",
       " 'i-org , shaken': 2.997601828609058e-08,\n",
       " 'i-org , kilos': 2.997601828609058e-08,\n",
       " 'i-org , maynard': 2.997601828609058e-08,\n",
       " 'i-org , joins': 2.997601828609058e-08,\n",
       " 'i-org , ours': 0.00029979015887919184,\n",
       " 'i-org , heads': 2.997601828609058e-08,\n",
       " 'i-org , 15-30': 2.997601828609058e-08,\n",
       " 'i-org , joaquin': 2.997601828609058e-08}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_emiss_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Exercise 2 ###################################################################\n",
    "''''\n",
    "Implement the Viterbi algorithm for computing the most likely state sequence given a sequence of observed symbols.\n",
    "Parameters: observed_smbols: list of strings; the sequence of observed symbols\n",
    "            initial_state_probabilities_parameters: data structure containing the parameters of the probability distribution of the initial states, returned by estimate_initial_state_probabilities\n",
    "            transition_probabilities_parameters: data structure containing the parameters of the matrix of transition probabilities, returned by estimate_transition_probabilities\n",
    "            emission_probabilities_parameters: data structure containing the parameters of the matrix of emission probabilities, returned by estimate_emission_probabilities\n",
    "Returns: list of strings; the most likely state sequence\n",
    "'''\n",
    "def most_likely_state_sequence(states,tokens,observed_symbols, initial_state_probabilities_parameters, transition_probabilities_parameters, emission_probabilities_parameters):\n",
    "    \n",
    "    for i,word in enumerate(observed_symbols): # check which word of the test sentence is not in corpus  \n",
    "        if word not in tokens:\n",
    "            observed_symbols[i]='unknown' \n",
    "\n",
    "    \n",
    "    \n",
    "    column1={}\n",
    "    max_states=[] \n",
    "    word=observed_symbols[0] # first word is treated separately since we don't have previous words and states to come from \n",
    "\n",
    "    for state in states:\n",
    "        delta = (log(initial_state_probabilities(state, initial_state_probabilities_parameters)) \n",
    "        + log(emission_probabilities(state, word, emission_probabilities_parameters )))\n",
    "\n",
    "        column1[state] = delta\n",
    "    \n",
    "    max_states.append(max(column1, key=column1.get)) # append the max state of the first column \n",
    "\n",
    "    for word in observed_symbols[1:]: \n",
    "        column2={}\n",
    "        for state_i in states:\n",
    "            prov_delta=[] # this is the current cell. This list will contain as many deltas as the number of distinct states\n",
    "            for state_j in states:\n",
    "                delta_ji = (column1[state_j]  +  \n",
    "                        log(transition_probabilities(state_j,state_i, transition_probabilities_parameters)) + \n",
    "                        log(emission_probabilities(state_i, word, emission_probabilities_parameters)))\n",
    "                \n",
    "                prov_delta.append(delta_ji) \n",
    "            \n",
    "            column2[state_i]= max(prov_delta) # max delta for the current cell\n",
    "        \n",
    "        max_states.append(max(column2, key=column2.get)) \n",
    "\n",
    "        column1=column2 # old column becomes the current column. The current column will become a new one in the next iteration\n",
    "\n",
    "    \n",
    "    return max_states\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'b-per', 'o', 'o', 'o', 'b-loc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=['hi', 'john', 'i', 'live', 'in', 'texas']\n",
    "\n",
    "most_likely_state_sequence(states, tokens, test, es_init_prob, es_trans_prob, es_emiss_prob)\n",
    "                           \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
